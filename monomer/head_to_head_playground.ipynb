{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations, permutations\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from fractions import Fraction\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "number2group={'TS002': 'JFK-THG-AMBER',\n",
    " 'TS003': 'JFK-THG-AMBERstable',\n",
    " 'TS004': 'JFK-THG-CHARMM',\n",
    " 'TS005': 'JFK-THG-CHARMMstable',\n",
    " 'TS006': 'RNA_Dojo',\n",
    " 'TS008': 'HADDOCK',\n",
    " 'TS014': 'Cool-PSP',\n",
    " 'TS015': 'PEZYFoldings',\n",
    " 'TS016': 'haiping',\n",
    " 'TS017': 'Seder2024hard',\n",
    " 'TS018': 'AttStructureScorer',\n",
    " 'TS019': 'Zheng-Server',\n",
    " 'TS020': 'comppharmunibas',\n",
    " 'TS022': 'Yang',\n",
    " 'TS023': 'FTBiot0119',\n",
    " 'TS026': 'SwRI',\n",
    " 'TS027': 'ModFOLDdock2R',\n",
    " 'TS028': 'NKRNA-s',\n",
    " 'TS029': 'zyh_mae_try1',\n",
    " 'TS030': 'SNU-CHEM_aff',\n",
    " 'TS031': 'MassiveFold',\n",
    " 'TS032': 'Bryant',\n",
    " 'TS033': 'Diff',\n",
    " 'TS039': 'arosko',\n",
    " 'TS040': 'DELCLAB',\n",
    "    'TS044': 'N/A',\n",
    " 'TS049': 'UTMB',\n",
    " 'TS050': 'SHORTLE',\n",
    " 'TS051': 'MULTICOM',\n",
    " 'TS052': 'Yang-Server',\n",
    " 'TS055': 'LCDD-team',\n",
    " 'TS059': 'DeepFold',\n",
    " 'TS063': 'RNApolis',\n",
    " 'TS074': 'ModFOLDdock2S',\n",
    " 'TS075': 'GHZ-ISM',\n",
    " 'TS077': 'coogs2',\n",
    " 'TS079': 'MRAFold',\n",
    " 'TS080': 'pDockQ',\n",
    " 'TS082': 'VnsDock',\n",
    " 'TS084': 'Vendruscolo',\n",
    " 'TS085': 'Bates',\n",
    " 'TS088': 'orangeballs',\n",
    " 'TS091': 'Huang-HUST',\n",
    " 'TS092': 'Seamount',\n",
    " 'TS094': 'SimRNA-server',\n",
    " 'TS097': 'JFK-THG-IDPCONFGEN',\n",
    " 'TS100': 'zurite_lab',\n",
    " 'TS102': 'Psi-Phi',\n",
    " 'TS105': 'PFSC-PFVM',\n",
    " 'TS110': 'MIEnsembles-Server',\n",
    " 'TS112': 'Seder2024easy',\n",
    " 'TS114': 'COAST',\n",
    " 'TS117': 'Vakser',\n",
    " 'TS120': 'Cerebra',\n",
    " 'TS121': 'Pascal_Auffinger',\n",
    " 'TS122': 'MQA_server',\n",
    " 'TS128': 'TheMeilerMethod',\n",
    " 'TS132': 'profold2',\n",
    " 'TS135': 'Lindorff-LarsenCLVDS',\n",
    " 'TS136': 'Lindorff-LarsenM3PPS',\n",
    " 'TS137': 'Lindorff-LarsenM3PWS',\n",
    " 'TS138': 'Shengyi',\n",
    " 'TS139': 'DeepFold-refine',\n",
    " 'TS143': 'dMNAfold',\n",
    " 'TS145': 'colabfold_baseline',\n",
    " 'TS147': 'Zheng-Multimer',\n",
    " 'TS148': 'Guijunlab-Complex',\n",
    " 'TS156': 'SoutheRNA',\n",
    " 'TS159': '406',\n",
    " 'TS163': 'MultiFOLD2',\n",
    " 'TS164': 'McGuffin',\n",
    " 'TS165': 'dfr',\n",
    " 'TS167': 'OpenComplex',\n",
    " 'TS169': 'thermomaps',\n",
    " 'TS171': 'ChaePred',\n",
    " 'TS172': 'VoroAffinity',\n",
    " 'TS174': 'colabfold_foldseek',\n",
    " 'TS177': 'aicb',\n",
    " 'TS183': 'GuangzhouRNA-human',\n",
    " 'TS187': 'Ayush',\n",
    " 'TS188': 'VifChartreuseJaune',\n",
    " 'TS189': 'LCBio',\n",
    " 'TS191': 'Schneidman',\n",
    " 'TS196': 'HYU_MLLAB',\n",
    " 'TS197': 'D3D',\n",
    " 'TS198': 'colabfold',\n",
    " 'TS201': 'Drugit',\n",
    " 'TS202': 'test001',\n",
    " 'TS204': 'Zou',\n",
    " 'TS207': 'MULTICOM_ligand',\n",
    " 'TS208': 'falcon2',\n",
    " 'TS209': 'colabfold_human',\n",
    " 'TS212': 'PIEFold_human',\n",
    " 'TS217': 'zyh_mae_try1E',\n",
    " 'TS218': 'HIT-LinYang',\n",
    " 'TS219': 'XGroup-server',\n",
    " 'TS221': 'CSSB_FAKER',\n",
    "    'TS225': 'N/A',\n",
    " 'TS226': 'Pfaender',\n",
    " 'TS227': 'KUMC',\n",
    " 'TS231': 'B-LAB',\n",
    " 'TS235': 'isyslab-hust',\n",
    " 'TS237': 'Convex-PL-R',\n",
    " 'TS238': 'BRIQX',\n",
    " 'TS241': 'elofsson',\n",
    " 'TS261': 'UNRES',\n",
    " 'TS262': 'CoDock',\n",
    " 'TS264': 'GuijunLab-Human',\n",
    " 'TS267': 'kiharalab_server',\n",
    " 'TS269': 'CSSB_server',\n",
    " 'TS271': 'mialab_prediction2',\n",
    " 'TS272': 'GromihaLab',\n",
    " 'TS273': 'MQA_base',\n",
    " 'TS274': 'kozakovvajda',\n",
    " 'TS275': 'Seminoles',\n",
    " 'TS276': 'FrederickFolding',\n",
    " 'TS281': 'T2DUCC',\n",
    " 'TS284': 'Unicorn',\n",
    " 'TS286': 'CSSB_experimental',\n",
    " 'TS287': 'plmfold',\n",
    " 'TS290': 'Pierce',\n",
    " 'TS293': 'MRAH',\n",
    " 'TS294': 'KiharaLab',\n",
    " 'TS295': 'VoroAffinityB',\n",
    " 'TS298': 'ShanghaiTech-human',\n",
    " 'TS300': 'ARC',\n",
    " 'TS301': 'GHZ-MAN',\n",
    " 'TS304': 'AF3-server',\n",
    " 'TS306': 'GeneSilicoRNA-server',\n",
    " 'TS307': 'nfRNA',\n",
    " 'TS308': 'MoMAteam1',\n",
    " 'TS309': 'Koes',\n",
    " 'TS311': 'RAGfold_Prot1',\n",
    " 'TS312': 'GuijunLab-Assembly',\n",
    " 'TS314': 'GuijunLab-PAthreader',\n",
    " 'TS317': 'GuangzhouRNA_AI',\n",
    " 'TS319': 'MULTICOM_LLM',\n",
    " 'TS322': 'XGroup',\n",
    " 'TS323': 'Yan',\n",
    " 'TS325': '405',\n",
    " 'TS331': 'MULTICOM_AI',\n",
    " 'TS337': 'APOLLO',\n",
    " 'TS338': 'GeneSilico',\n",
    " 'TS345': 'MULTICOM_human',\n",
    " 'TS349': 'cheatham-lab',\n",
    " 'TS351': 'digiwiser-ensemble',\n",
    " 'TS353': 'KORP-PL-W',\n",
    " 'TS355': 'CMOD',\n",
    " 'TS357': 'UTAustin',\n",
    " 'TS358': 'PerezLab_Gators',\n",
    " 'TS361': 'Cerebra_server',\n",
    " 'TS363': '2Vinardo',\n",
    " 'TS367': 'AIR',\n",
    " 'TS369': 'Bhattacharya',\n",
    " 'TS370': 'DrAshokAndFriends',\n",
    " 'TS375': 'milliseconds',\n",
    " 'TS376': 'OFsingleseq',\n",
    " 'TS380': 'mialab_prediction',\n",
    " 'TS384': 'pert-plddt',\n",
    " 'TS386': 'ShanghaiTech-Ligand',\n",
    " 'TS388': 'DeepFold-server',\n",
    " 'TS391': 'bussilab_replex',\n",
    " 'TS393': 'GuijunLab-QA',\n",
    " 'TS397': 'smg_ulaval',\n",
    " 'TS400': 'OmniFold',\n",
    " 'TS403': 'mmagnus',\n",
    " 'TS408': 'SNU-CHEM-lig',\n",
    " 'TS412': 'cheatham-lab_villa',\n",
    " 'TS416': 'GPLAffinity',\n",
    " 'TS417': 'GuangzhouRNA-meta',\n",
    " 'TS418': 'Lee-Shin',\n",
    " 'TS419': 'CSSB-Human',\n",
    " 'TS420': 'Zou_aff2',\n",
    " 'TS423': 'ShanghaiTech-server',\n",
    " 'TS425': 'MULTICOM_GATE',\n",
    " 'TS432': 'DIMAIO',\n",
    " 'TS435': 'RNAFOLDX',\n",
    " 'TS436': 'Yoshiaki',\n",
    " 'TS439': 'Dokholyan',\n",
    " 'TS441': 'ModFOLDdock2',\n",
    " 'TS443': 'MQA',\n",
    " 'TS446': 'pDockQ2',\n",
    " 'TS447': 'UDMod',\n",
    " 'TS448': 'dNAfold',\n",
    " 'TS450': 'OpenComplex_Server',\n",
    " 'TS456': 'Yang-Multimer',\n",
    " 'TS461': 'forlilab',\n",
    " 'TS462': 'Zheng',\n",
    " 'TS464': 'PocketTracer',\n",
    " 'TS465': 'Wallner',\n",
    " 'TS466': 'coogs3',\n",
    " 'TS468': 'MIALAB_gong',\n",
    " 'TS469': 'GruLab',\n",
    " 'TS471': 'Pcons',\n",
    " 'TS474': 'CCB-AlGDock',\n",
    " 'TS475': 'ptq',\n",
    " 'TS476': 'VifChartreuse',\n",
    " 'TS481': 'Vfold',\n",
    " 'TS485': 'bussilab_plain_md',\n",
    " 'TS489': 'Fernandez-Recio',\n",
    " 'TS494': 'ClusPro',\n",
    " 'TS496': 'AF_unmasked'}\n",
    "\n",
    "model = \"first\"\n",
    "model = \"best\"\n",
    "\n",
    "mode = \"easy\"\n",
    "# mode = \"medium\"\n",
    "# mode = \"difficult\"\n",
    "# mode = \"all\"\n",
    "\n",
    "phase = \"0\"\n",
    "phase = \"1\"\n",
    "phase = \"2\"\n",
    "phase = \"0,1,2\"\n",
    "\n",
    "top_n = 28\n",
    "\n",
    "impute_value = -2\n",
    "os.chdir(\"/home2/s439906/project/CASP16/monomer/\")\n",
    "path = \"./monomer_data_newest/processed/\"\n",
    "\n",
    "\n",
    "parameters = [\n",
    "    [\"best\", \"all\", \"1\", 28, -2],\n",
    "    [\"best\", \"all\", \"0,1,2\", 28, -2],\n",
    "    [\"first\", \"all\", \"0,1,2\", 28, -2],\n",
    "    [\"best\", \"all\", \"0\", 28, -2],\n",
    "    [\"best\", \"all\", \"1\", 28, -2],\n",
    "    [\"best\", \"all\", \"2\", 28, -2],\n",
    "    [\"best\", \"easy\", \"0,1,2\", 28, -2],\n",
    "    [\"best\", \"medium\", \"0,1,2\", 28, -2],\n",
    "    [\"best\", \"difficult\", \"0,1,2\", 28, -2],\n",
    "    ]\n",
    "for parameter in parameters:\n",
    "    model = parameter[0]\n",
    "    mode = parameter[1]\n",
    "    phase = parameter[2]\n",
    "    top_n = parameter[3]\n",
    "    impute_value = parameter[4]\n",
    "    metadata_file = \"./monomer_EU_info\"\n",
    "    EU_weight = {}\n",
    "    with open(metadata_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"T\"):\n",
    "                words = line.strip().split()\n",
    "                protein = words[0]\n",
    "                if protein == \"T1249\":\n",
    "                    protein = \"T1249v1\"\n",
    "                if protein == \"T2249\":\n",
    "                    protein = \"T2249v1\"\n",
    "                domain = words[1]\n",
    "                difficulty = words[2]\n",
    "                weight = float(Fraction(words[4]))\n",
    "                EU = f\"{protein}-{domain}\"\n",
    "                EU_weight[EU] = weight\n",
    "\n",
    "    difficulty_group = {\"easy\": [], \"medium\": [], \"difficult\": []}\n",
    "    difficulty_file = \"./step7_result\"\n",
    "    with open(difficulty_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"T\"):\n",
    "                words = line.strip().split()\n",
    "                protein = words[0]\n",
    "                if protein == \"T1249-D1\":\n",
    "                    protein = \"T1249v1-D1\"\n",
    "                if protein == \"T2249-D1\":\n",
    "                    protein = \"T2249v1-D1\"\n",
    "                difficulty = words[2]\n",
    "                EU = protein\n",
    "                if difficulty == \"easy\":\n",
    "                    difficulty_group[difficulty].append(EU)\n",
    "                elif difficulty == \"medium\":\n",
    "                    difficulty_group[difficulty].append(EU)\n",
    "                elif difficulty == \"hard\":\n",
    "                    difficulty_group[\"difficult\"].append(EU)\n",
    "\n",
    "    files = [file for file in os.listdir(path) if file.startswith(\"T\") and file.endswith(\".csv\")]\n",
    "    files.sort()\n",
    "\n",
    "    if mode == \"easy\":\n",
    "        files = [file for file in files if file[:-4] in difficulty_group[\"easy\"]]\n",
    "    elif mode == \"medium\":\n",
    "        files = [file for file in files if file[:-4] in difficulty_group[\"medium\"]]\n",
    "    elif mode == \"difficult\":\n",
    "        files = [file for file in files if file[:-4] in difficulty_group[\"difficult\"]]\n",
    "    elif mode == \"all\":\n",
    "        pass\n",
    "    if phase == \"0\":\n",
    "        files = [file for file in files if file.startswith(\"T0\")]\n",
    "    elif phase == \"1\":\n",
    "        files = [file for file in files if file.startswith(\"T1\")]\n",
    "    elif phase == \"2\":\n",
    "        files = [file for file in files if file.startswith(\"T2\")]\n",
    "    elif phase == \"0,1,2\":\n",
    "        pass\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    for file in files:\n",
    "        df_tmp = pd.read_csv(path + file, index_col=0)\n",
    "        df = pd.concat([df, df_tmp])\n",
    "    df.index = df.index.str.extract(\n",
    "        r'(T\\w+)TS(\\w+)_(\\w+)(?:-(.*))?').apply(lambda x: (f\"{x[0]}-{x[3]}\" if pd.notna(x[3]) else x[0], f\"TS{x[1]}\", x[2]), axis=1)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    for file in files:\n",
    "        df_tmp = pd.read_csv(path + file, index_col=0)\n",
    "        df = pd.concat([df, df_tmp])\n",
    "    df.index = df.index.str.extract(\n",
    "        r'(T\\w+)TS(\\w+)_(\\w+)(?:-(.*))?').apply(lambda x: (f\"TS{x[1]}\", f\"{x[0]}-{x[3]}\" if pd.notna(x[3]) else x[0],  x[2]), axis=1)\n",
    "    # sort index\n",
    "    df = df.sort_index()\n",
    "    df.index = pd.MultiIndex.from_tuples(\n",
    "                df.index, names=['group', 'target', 'model'])\n",
    "\n",
    "\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for file in files:\n",
    "        df_tmp = pd.read_csv(os.path.join(path, file), index_col=0)\n",
    "        df = pd.concat([df, df_tmp])\n",
    "\n",
    "    df.index = df.index.str.extract(\n",
    "        r'(T\\w+)TS(\\w+)_(\\w+)(?:-(.*))?'\n",
    "    ).apply(lambda x: (f\"TS{x[1]}\", f\"{x[0]}-{x[3]}\" if pd.notna(x[3]) else x[0], x[2]), axis=1)\n",
    "\n",
    "    df = df.sort_index()\n",
    "\n",
    "    df.index = pd.MultiIndex.from_tuples(\n",
    "        df.index, names=['group', 'target', 'model']\n",
    "    )\n",
    "\n",
    "    # check the number of targets in each group\n",
    "    group_target_counts = df.index.get_level_values('group').value_counts()\n",
    "\n",
    "    len(files)\n",
    "\n",
    "    # do bootstrap\n",
    "    weights = [\n",
    "                            1/6, 1/16, 1/6,\n",
    "                            1/6,\n",
    "                            1/16, 1/8,\n",
    "                            1/8, 1/16,\n",
    "                            1/16,\n",
    "                        ]\n",
    "    group_dict = {}\n",
    "    for file in files:\n",
    "        EU = file.split('.')[0]\n",
    "        with open(path + file, 'r') as f:\n",
    "            for line in f:\n",
    "                if line.startswith(\"T\"):\n",
    "                    word = line.strip().split(',')\n",
    "                    meta_data = word[0]\n",
    "                    _, meta_data = meta_data.split('TS')\n",
    "                    group, model_id = meta_data.split('_')\n",
    "                    group = 'TS' + group\n",
    "                    model_id = model_id[0]\n",
    "                    if group not in group_dict:\n",
    "                        group_dict[group] = {}\n",
    "                    if EU not in group_dict[group]:\n",
    "                        group_dict[group][EU] = {}\n",
    "                    score = sum([float(word[i+1] )* weights[i] for i in range(9)]) * EU_weight[EU] \n",
    "                    if model_id not in group_dict[group][EU]:\n",
    "                        group_dict[group][EU][model_id] = score\n",
    "                    else:\n",
    "                        group_dict[group][EU][model_id] = max(score, group_dict[group][EU][model_id])\n",
    "        # if there is no model_1, replace the model with the smallest id to be model_1\n",
    "        for group in group_dict:\n",
    "            for EU in group_dict[group]:\n",
    "                if '1' not in group_dict[group][EU]:\n",
    "                    min_model = min(group_dict[group][EU], key=group_dict[group][EU].get)\n",
    "                    group_dict[group][EU]['1'] = group_dict[group][EU][min_model]\n",
    "                    del group_dict[group][EU][min_model]\n",
    "    \n",
    "    # to_del = []\n",
    "    # # print the groups that has less than 37 targets\n",
    "    # for group in group_dict:\n",
    "    #     if len(group_dict[group]) <= 55:\n",
    "    #         print(group, len(group_dict[group]))\n",
    "    #         to_del.append(group)\n",
    "    # for group in to_del:\n",
    "    #     del group_dict[group]\n",
    "\n",
    "    group_dict = dict(sorted(group_dict.items(), key=lambda x: x[0]))\n",
    "    group_dict\n",
    "    score_path = \"./score_all/\"\n",
    "    ranking_file = f\"sum-{model}-{mode}-{phase}-impute={impute_value}-EU_weighted_sum.csv\"\n",
    "    ranking_info = pd.read_csv(score_path + ranking_file, index_col=0)\n",
    "    ranking_info\n",
    "    top_n_list = ranking_info.index[:top_n].tolist()\n",
    "    top_n_list\n",
    "    group_dict = {k: v for k, v in group_dict.items() if k in top_n_list}\n",
    "    assert len(group_dict) == top_n\n",
    "\n",
    "    bootstrap_dict  = {}\n",
    "    for group_1 in group_dict.keys():\n",
    "        bootstrap_dict[group_1] = {}\n",
    "        for group_2 in group_dict.keys():\n",
    "            bootstrap_dict[group_1][group_2] = 0\n",
    "        \n",
    "    bootstrap_round = 1000\n",
    "    for i in range(bootstrap_round):\n",
    "        for group_1, group_2 in combinations(group_dict.keys(), 2):\n",
    "            data_1 = group_dict[group_1]\n",
    "            data_2 = group_dict[group_2]\n",
    "            common_EU = set(data_1.keys()) & set(data_2.keys())\n",
    "            sampled_EU = random.choices(list(common_EU), k=len(common_EU))\n",
    "            score_1 = 0\n",
    "            score_2 = 0\n",
    "            for eu in sampled_EU:\n",
    "                value_dict_1 = data_1[eu]\n",
    "                value_dict_2 = data_2[eu]\n",
    "                # print(value_list_1)\n",
    "                # print(value_list_2)\n",
    "                # sampled_value_1 = random.choice(value_list_1)\n",
    "                # sampled_value_2 = random.choice(value_list_2)\n",
    "                # sampled_value_1 =  max(value_dict_1.values())\n",
    "                # sampled_value_2 =  max(value_dict_2.values())\n",
    "                # sampled_value_1 = value_list_1['1']\n",
    "                # sampled_value_2 = value_list_2['1']\n",
    "                if model == \"first\":\n",
    "                    sampled_value_1 = value_dict_1['1']\n",
    "                    sampled_value_2 = value_dict_2['1']\n",
    "                elif model == \"best\":\n",
    "                    # take the common keys in the two dicts\n",
    "                    common_keys = set(value_dict_1.keys()) & set(value_dict_2.keys())\n",
    "                    # get the best score in the common keys\n",
    "                    sampled_value_1 = max([value_dict_1[key] for key in common_keys])\n",
    "                    sampled_value_2 = max([value_dict_2[key] for key in common_keys])\n",
    "                score_1 += sampled_value_1\n",
    "                score_2 += sampled_value_2\n",
    "            if score_1 > score_2:\n",
    "                if group_1 not in bootstrap_dict:\n",
    "                    bootstrap_dict[group_1] = {}\n",
    "                if group_2 not in bootstrap_dict[group_1]:\n",
    "                    bootstrap_dict[group_1][group_2] = 0\n",
    "                bootstrap_dict[group_1][group_2] += 1\n",
    "            elif score_1 < score_2:\n",
    "                if group_2 not in bootstrap_dict:\n",
    "                    bootstrap_dict[group_2] = {}\n",
    "                if group_1 not in bootstrap_dict[group_2]:\n",
    "                    bootstrap_dict[group_2][group_1] = 0\n",
    "                bootstrap_dict[group_2][group_1] += 1\n",
    "            else:\n",
    "                if group_1 not in bootstrap_dict:\n",
    "                    bootstrap_dict[group_1] = {}\n",
    "                if group_2 not in bootstrap_dict[group_1]:\n",
    "                    bootstrap_dict[group_1][group_2] = 0\n",
    "                bootstrap_dict[group_1][group_2] += 0.5\n",
    "                if group_2 not in bootstrap_dict:\n",
    "                    bootstrap_dict[group_2] = {}\n",
    "                if group_1 not in bootstrap_dict[group_2]:\n",
    "                    bootstrap_dict[group_2][group_1] = 0\n",
    "                bootstrap_dict[group_2][group_1] += 0.5\n",
    "\n",
    "        if i % 100 == 99:\n",
    "            print(f\"Bootstrap {i+1} done.\")\n",
    "    bootstrap_dict\n",
    "\n",
    "    # get bootstrap rank\n",
    "    for group_1 in bootstrap_dict:\n",
    "        for group_2 in bootstrap_dict[group_1]:\n",
    "            bootstrap_dict[group_1][group_2] /= bootstrap_round\n",
    "    bootstrap_sum = {}\n",
    "    for group_1 in bootstrap_dict:\n",
    "        for group_2 in bootstrap_dict[group_1]:\n",
    "            if group_1 not in bootstrap_sum:\n",
    "                bootstrap_sum[group_1] = 0\n",
    "            bootstrap_sum[group_1] += bootstrap_dict[group_1][group_2]\n",
    "            \n",
    "    # sort the dict by value\n",
    "    bootstrap_sum = dict(sorted(bootstrap_sum.items(), key=lambda x: x[1], reverse=True))\n",
    "    bootstrap_sum\n",
    "\n",
    "\n",
    "\n",
    "    # PLOT\n",
    "    \n",
    "    # rank bootstrap_dict by bootstrap_sum\n",
    "    bootstrap_rank = [key for key in bootstrap_sum]\n",
    "    bootstrap_dict = dict(sorted(bootstrap_dict.items(), key=lambda x: bootstrap_sum[x[0]], reverse=True))\n",
    "    for group in bootstrap_dict:\n",
    "        bootstrap_dict[group] = dict(sorted(bootstrap_dict[group].items(), key=lambda x: bootstrap_sum[x[0]],reverse=True))\n",
    "    # convert it to an numpy array\n",
    "    bootstrap_array = np.zeros((top_n, top_n))\n",
    "    for i, group_1 in enumerate(bootstrap_dict):\n",
    "        for j, group_2 in enumerate(bootstrap_dict[group_1]):\n",
    "            bootstrap_array[i, j] = bootstrap_dict[group_1][group_2]\n",
    "    bootstrap_array,bootstrap_rank\n",
    "    \n",
    "    bootstrap_rank = [number2group[i] for i in bootstrap_rank]\n",
    "    # top_n_id = groups[:top_n]\n",
    "    # top_n_id = [i.replace(\"TS\", \"\") for i in top_n_id]\n",
    "    # win_matrix = np.array(win_matrix)\n",
    "    # win_matrix_top_n = win_matrix[:top_n, :top_n]\n",
    "    # win_matrix_top_n = win_matrix_top_n / bootstrap_rounds\n",
    "\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    ax = sns.heatmap(bootstrap_array, annot=True, fmt=\".2f\",\n",
    "                    cmap='Greys', cbar=True, square=True,\n",
    "                    xticklabels=bootstrap_rank, yticklabels=bootstrap_rank,\n",
    "                    #   linewidths=1, linecolor='black',\n",
    "                    )\n",
    "\n",
    "    for text in ax.texts:\n",
    "        value = float(text.get_text())\n",
    "        if value >= 0.95:\n",
    "            text.set_color('red')\n",
    "        elif value < 0.95 and value >= 0.75:\n",
    "            text.set_color('white')\n",
    "        else:\n",
    "            text.set_color('black')\n",
    "\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.set_ticks([0, float(1/4), float(1/2),\n",
    "                    float(3/4), 1])\n",
    "    cbar.set_ticklabels([0, float(1/4), float(1/2),\n",
    "                        float(3/4), 1])\n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "    for _, spine in ax.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_linewidth(2)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=90, fontsize=12)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), rotation=0, fontsize=12)\n",
    "    # plt.xticks(np.arange(top_n), bootstrap_rank,rotation=90, fontsize=18)\n",
    "    # plt.yticks(np.arange(top_n), bootstrap_rank, rotation=0, fontsize=18)\n",
    "    plt.title(f\"models: {model}, targets: {mode}, top_n: {top_n}, phase: {phase}, impute: {impute_value}\", fontsize=20, pad=30)\n",
    "    # if equal_weight:\n",
    "    #     plt.title(\"bootstrap result of {} score for {} models, {} targets, top {} groups, equal weight\".format(\n",
    "    #         measure_type, model, mode, top_n), fontsize=16, pad=20)\n",
    "    # else:\n",
    "    #     plt.title(\"bootstrap result of {} score for {} models, {} targets, top {} groups\".format(\n",
    "    #         measure_type, model, mode, top_n), fontsize=16, pad=20)\n",
    "    fig_path = \"./CASP16_figures/\"\n",
    "    png_top_file = f\"bootstrap_{model}_{mode}_{phase}_impute={impute_value}_top_{top_n}.png\"\n",
    "    plt.savefig(fig_path + png_top_file, dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit(0)\n",
    "weights = [\n",
    "                        1/6, 1/16, 1/6,\n",
    "                        1/6,\n",
    "                        1/16, 1/8,\n",
    "                        1/8, 1/16,\n",
    "                        1/16,\n",
    "                    ]\n",
    "group_dict = {}\n",
    "for file in files:\n",
    "    EU = file.split('.')[0]\n",
    "    with open(path + file, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"T\"):\n",
    "                word = line.strip().split(',')\n",
    "                meta_data = word[0]\n",
    "                _, meta_data = meta_data.split('TS')\n",
    "                group = meta_data.split('_')[0]\n",
    "                group = 'TS' + group\n",
    "                if group not in group_dict:\n",
    "                    group_dict[group] = {}\n",
    "                if EU not in group_dict[group]:\n",
    "                    group_dict[group][EU] = []\n",
    "                # print(word)\n",
    "                # print([word[i+1] * weights[i] for i in range(9)])\n",
    "                group_dict[group][EU].append(sum([float(word[i+1] )* weights[i]*EU_weight[EU] for i in range(9)]))\n",
    "\n",
    "# to_del = []\n",
    "# # print the groups that has less than 37 targets\n",
    "# for group in group_dict:\n",
    "#     if len(group_dict[group]) <= 107:\n",
    "#         # print(group, len(group_dict[group]))\n",
    "#         to_del.append(group)\n",
    "# for group in to_del:\n",
    "#     del group_dict[group]\n",
    "# group_dict = dict(sorted(group_dict.items(), key=lambda x: x[0]))\n",
    "\n",
    "score_path = \"./score_all/\"\n",
    "ranking_file = f\"sum-{model}-{mode}-{phase}-impute={impute_value}-EU_weighted_sum.csv\"\n",
    "ranking_info = pd.read_csv(score_path + ranking_file, index_col=0)\n",
    "ranking_info\n",
    "top_n_list = ranking_info.index[:top_n].tolist()\n",
    "top_n_list\n",
    "group_dict = {k: v for k, v in group_dict.items() if k in top_n_list}\n",
    "assert len(group_dict) == top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_dict  = {}\n",
    "for i in range(1):\n",
    "    for group_1, group_2 in combinations(group_dict.keys(), 2):\n",
    "        data_1 = group_dict[group_1]\n",
    "        data_2 = group_dict[group_2]\n",
    "        common_EU = set(data_1.keys()) & set(data_2.keys())\n",
    "        sampled_EU = random.choices(list(common_EU), k=len(common_EU))\n",
    "        score_1 = 0\n",
    "        score_2 = 0\n",
    "        for eu in sampled_EU:\n",
    "            value_list_1 = data_1[eu]\n",
    "            value_list_2 = data_2[eu]\n",
    "            # sampled_value_1 = random.choice(value_list_1)\n",
    "            # sampled_value_2 = random.choice(value_list_2)\n",
    "            # sampled_value_1 = max(value_list_1)\n",
    "            # sampled_value_2 = max(value_list_2)\n",
    "\n",
    "            if len(value_list_1) != len(value_list_2):\n",
    "                if len(value_list_1) > len(value_list_2):\n",
    "                    # first make sample list 1 to be the same length as sample list 2 without putting back\n",
    "                    value_list_1_tmp = random.sample(value_list_1, len(value_list_2))\n",
    "                    sampled_value_1 = max(value_list_1_tmp)\n",
    "                    sampled_value_2 = max(value_list_2)\n",
    "                else:\n",
    "                    value_list_2_tmp = random.sample(value_list_2, len(value_list_1))\n",
    "                    sampled_value_1 = max(value_list_1)\n",
    "                    sampled_value_2 = max(value_list_2_tmp)\n",
    "            else:\n",
    "                sampled_value_1 = max(value_list_1)\n",
    "                sampled_value_2 = max(value_list_2)\n",
    "            score_1 += sampled_value_1\n",
    "            score_2 += sampled_value_2\n",
    "        if score_1 > score_2:\n",
    "            if group_1 not in bootstrap_dict:\n",
    "                bootstrap_dict[group_1] = {}\n",
    "            if group_2 not in bootstrap_dict[group_1]:\n",
    "                bootstrap_dict[group_1][group_2] = 0\n",
    "            bootstrap_dict[group_1][group_2] += 1\n",
    "        elif score_1 < score_2:\n",
    "            if group_2 not in bootstrap_dict:\n",
    "                bootstrap_dict[group_2] = {}\n",
    "            if group_1 not in bootstrap_dict[group_2]:\n",
    "                bootstrap_dict[group_2][group_1] = 0\n",
    "            bootstrap_dict[group_2][group_1] += 1\n",
    "        else:\n",
    "            if group_1 not in bootstrap_dict:\n",
    "                bootstrap_dict[group_1] = {}\n",
    "            if group_2 not in bootstrap_dict[group_1]:\n",
    "                bootstrap_dict[group_1][group_2] = 0\n",
    "            bootstrap_dict[group_1][group_2] += 0.5\n",
    "            if group_2 not in bootstrap_dict:\n",
    "                bootstrap_dict[group_2] = {}\n",
    "            if group_1 not in bootstrap_dict[group_2]:\n",
    "                bootstrap_dict[group_2][group_1] = 0\n",
    "            bootstrap_dict[group_2][group_1] += 0.5\n",
    "\n",
    "\n",
    "    print(f\"Bootstrap {i+1} done.\")\n",
    "bootstrap_sum = {}\n",
    "for group_1 in bootstrap_dict:\n",
    "    for group_2 in bootstrap_dict[group_1]:\n",
    "        if group_1 not in bootstrap_sum:\n",
    "            bootstrap_sum[group_1] = 0\n",
    "        bootstrap_sum[group_1] += bootstrap_dict[group_1][group_2]\n",
    "# sort the dict by value\n",
    "bootstrap_sum = dict(sorted(bootstrap_sum.items(), key=lambda x: x[1], reverse=True))\n",
    "print(bootstrap_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_points = {}\n",
    "for group in group_dict:\n",
    "    for EU in group_dict[group]:\n",
    "        if group not in group_points:\n",
    "            group_points[group] = 0\n",
    "        print(group_dict[group][EU].__len__())\n",
    "        group_points[group] += max(group_dict[group][EU])\n",
    "        break\n",
    "    break\n",
    "group_points = dict(sorted(group_points.items(), key=lambda x: x[1], reverse=True))\n",
    "group_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_dict = {}\n",
    "# for file in files:\n",
    "#     EU = file.split('.')[0]\n",
    "#     with open(path + file, 'r') as f:\n",
    "#         for line in f:\n",
    "#             if line.startswith(\"T\"):\n",
    "#                 word = line.strip().split(',')\n",
    "#                 meta_data = word[0]\n",
    "#                 _, meta_data = meta_data.split('TS')\n",
    "#                 group = meta_data.split('_')[0]\n",
    "#                 group = 'TS' + group\n",
    "#                 if group not in group_dict:\n",
    "#                     group_dict[group] = {}\n",
    "#                 if EU not in group_dict[group]:\n",
    "#                     group_dict[group][EU] = []\n",
    "#                 group_dict[group][EU].append(word[1:])\n",
    "# to_del = []\n",
    "# # print the groups that has less than 37 targets\n",
    "# for group in group_dict:\n",
    "#     if len(group_dict[group]) <= 70:\n",
    "#         # print(group, len(group_dict[group]))\n",
    "#         to_del.append(group)\n",
    "# for group in to_del:\n",
    "#     del group_dict[group]\n",
    "\n",
    "# group_dict = dict(sorted(group_dict.items(), key=lambda x: x[0]))\n",
    "# weights = [\n",
    "#                         1/6, 1/16, 1/6,\n",
    "#                         1/6,\n",
    "#                         1/16, 1/8,\n",
    "#                         1/8, 1/16,\n",
    "#                         1/16,\n",
    "#                     ]\n",
    "# # get a n*n matrix to store bootstrap results\n",
    "# # n = len(group_dict)\n",
    "# # bootstrap_results = np.zeros((n, n))\n",
    "# bootstrap_dict  = {}\n",
    "# for i in range(2):\n",
    "#     for group_1, group_2 in combinations(group_dict.keys(), 2):\n",
    "#         data_1 = group_dict[group_1]\n",
    "#         data_2 = group_dict[group_2]\n",
    "#         # 获取共有的 EU\n",
    "#         common_EU = set(data_1.keys()) & set(data_2.keys())\n",
    "#         # 随机有放回地抽取 len(common_EU) 个 EU\n",
    "#         sampled_EU = random.choices(list(common_EU), k=len(common_EU))\n",
    "#         score_1 = 0\n",
    "#         score_2 = 0\n",
    "#         # 对于每个抽取的 EU，取出对应的值，然后从值的列表中随机抽取一个\n",
    "#         for eu in sampled_EU:\n",
    "#             value_list_1 = data_1[eu]\n",
    "#             value_list_2 = data_2[eu]\n",
    "#             sampled_value_1 = random.choice(value_list_1)\n",
    "#             sampled_value_2 = random.choice(value_list_2)\n",
    "#             weighed_sum_1 = np.sum([float(x) * y for x, y in zip(sampled_value_1, weights)])\n",
    "#             weighed_sum_2 = np.sum([float(x) * y for x, y in zip(sampled_value_2, weights)])\n",
    "#             score_1 += float(weighed_sum_1)\n",
    "#             score_2 += float(weighed_sum_2)\n",
    "#         if score_1 > score_2:\n",
    "#             if group_1 not in bootstrap_dict:\n",
    "#                 bootstrap_dict[group_1] = {}\n",
    "#             if group_2 not in bootstrap_dict[group_1]:\n",
    "#                 bootstrap_dict[group_1][group_2] = 0\n",
    "#             bootstrap_dict[group_1][group_2] += 1\n",
    "#         elif score_1 < score_2:\n",
    "#             if group_2 not in bootstrap_dict:\n",
    "#                 bootstrap_dict[group_2] = {}\n",
    "#             if group_1 not in bootstrap_dict[group_2]:\n",
    "#                 bootstrap_dict[group_2][group_1] = 0\n",
    "#             bootstrap_dict[group_2][group_1] += 1\n",
    "#         else:\n",
    "#             if group_1 not in bootstrap_dict:\n",
    "#                 bootstrap_dict[group_1] = {}\n",
    "#             if group_2 not in bootstrap_dict[group_1]:\n",
    "#                 bootstrap_dict[group_1][group_2] = 0\n",
    "#             bootstrap_dict[group_1][group_2] += 0.5\n",
    "#             if group_2 not in bootstrap_dict:\n",
    "#                 bootstrap_dict[group_2] = {}\n",
    "#             if group_1 not in bootstrap_dict[group_2]:\n",
    "#                 bootstrap_dict[group_2][group_1] = 0\n",
    "#             bootstrap_dict[group_2][group_1] += 0.5\n",
    "\n",
    "\n",
    "#     print(f\"Bootstrap {i+1} done.\")\n",
    "\n",
    "# bootstrap_sum = {}\n",
    "# for group_1 in bootstrap_dict:\n",
    "#     for group_2 in bootstrap_dict[group_1]:\n",
    "#         if group_1 not in bootstrap_sum:\n",
    "#             bootstrap_sum[group_1] = 0\n",
    "#         bootstrap_sum[group_1] += bootstrap_dict[group_1][group_2]\n",
    "# # sort the dict by value\n",
    "# bootstrap_sum = dict(sorted(bootstrap_sum.items(), key=lambda x: x[1], reverse=True))\n",
    "# bootstrap_sum"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
