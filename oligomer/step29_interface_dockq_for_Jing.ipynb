{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "os.chdir(\"/home2/s439906/project/CASP16/monomer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"/data/data1/conglab/jzhan6/CASP16/targetPDBs/Targets_oligo_interfaces_20240917/nr_interfaces/\"\n",
    "result_files = [result for result in os.listdir(results_dir) if result.endswith(\".nr_interface.results\")]\n",
    "stage=\"1\"\n",
    "bad_targets= [\n",
    "    \"T1246\",\n",
    "    \"T1269v1o_\",\n",
    "    \"T1295o.\",\n",
    "    \"H1265_\",\n",
    "    \"T2270o\",\n",
    "]\n",
    "if stage == \"1\":\n",
    "    bad_targets.extend([\n",
    "        \"T0\",\n",
    "        \"T2\",\n",
    "        \"H0\",\n",
    "        \"H2\"\n",
    "    ])\n",
    "elif stage == \"0\":\n",
    "    bad_targets.extend([\n",
    "        \"T1\",\n",
    "        \"T2\",\n",
    "        \"H1\",\n",
    "        \"H2\"\n",
    "    ])\n",
    "elif stage == \"2\":\n",
    "    bad_targets.extend([\n",
    "        \"T0\",\n",
    "        \"T1\",\n",
    "        \"H0\",\n",
    "        \"H1\"\n",
    "    ])\n",
    "else:\n",
    "    print(\"Invalid stage\")\n",
    "    sys.exit(1)\n",
    "\n",
    "to_remove = []\n",
    "for result_file in result_files:\n",
    "    for removed_target in bad_targets:\n",
    "        if result_file.startswith(removed_target):\n",
    "            to_remove.append(result_file)\n",
    "            break\n",
    "for remove in to_remove:\n",
    "    result_files.remove(remove)\n",
    "result_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 创建用于存储每个统计结果的 DataFrame\n",
    "min_df = pd.DataFrame()\n",
    "max_df = pd.DataFrame()\n",
    "mean_df = pd.DataFrame()\n",
    "final_max_dockq_df = pd.DataFrame()\n",
    "\n",
    "# 循环读取每个 TSV 文件\n",
    "for result_file in result_files:\n",
    "    target = result_file.split(\".\")[0]  # 使用文件名作为目标名称\n",
    "    data = pd.read_csv(os.path.join(results_dir, result_file), sep=\"\\t\")\n",
    "    # 获取同时满足 dockq_mean 列存在且 model 列中包含 'TS145' 的部分\n",
    "    filtered_data = data[data['model'].str.contains('TS145', na=False)]\n",
    "    \n",
    "    if filtered_data.empty:\n",
    "        print(f\"No models containing 'TS145' found in {result_file}.\")\n",
    "    else:\n",
    "        filtered_data.set_index('model', inplace=True)\n",
    "        dockq_mean_filtered = filtered_data['dockq_mean']\n",
    "        \n",
    "        # 将非字符串类型转换为字符串类型，以便进行字符串操作\n",
    "        dockq_mean_filtered = dockq_mean_filtered.astype(str)\n",
    "        \n",
    "        # 检查 dockq_mean 列中是否存在 None 或 'None' 字符串\n",
    "        if dockq_mean_filtered.str.contains('None').any():\n",
    "            print(f\"Warning: 'dockq_mean' column in {result_file} contains 'None' as a string value.\")\n",
    "        \n",
    "        # 检查并移除 dockq_mean 列中包含 '-' 字符的行\n",
    "        if dockq_mean_filtered.str.contains('-').any():\n",
    "            print(f\"Warning: 'dockq_mean' column in {result_file} contains '-' as a character. Removing these rows.\")\n",
    "            filtered_data = filtered_data[~dockq_mean_filtered.str.contains('-')]\n",
    "            dockq_mean_filtered = filtered_data['dockq_mean'].astype(str)\n",
    "        \n",
    "        # 将 dockq_mean 列中的值按分号拆分，每个值成为一个新列\n",
    "        dockq_mean_split = dockq_mean_filtered.str.split(';', expand=True)\n",
    "        dockq_mean_split.columns = [f'{target}_dockq_mean_interface_{i+1}' for i in range(dockq_mean_split.shape[1])]\n",
    "        \n",
    "        dockq_mean_filtered = pd.DataFrame(dockq_mean_filtered)\n",
    "        result_with_split = dockq_mean_filtered.join(dockq_mean_split)\n",
    "        \n",
    "        # 移除 dockq_mean 列\n",
    "        result_with_split.drop(columns=['dockq_mean'], inplace=True)\n",
    "\n",
    "        # 将列转换为浮点数类型以进行统计计算\n",
    "        result_with_split = result_with_split.apply(pd.to_numeric, errors='coerce')\n",
    "        \n",
    "        # 计算每列的最小值、最大值和均值，并存储到对应的 DataFrame 中，同时设置行索引为 target\n",
    "        min_row = pd.DataFrame(result_with_split.min()).transpose()\n",
    "        min_row.index = ['TS145']\n",
    "        min_df = pd.concat([min_df, min_row], axis=1)\n",
    "        \n",
    "        max_row = pd.DataFrame(result_with_split.max()).transpose()\n",
    "        max_row.index = ['TS145']\n",
    "        max_df = pd.concat([max_df, max_row], axis=1)\n",
    "        \n",
    "        mean_row = pd.DataFrame(result_with_split.mean()).transpose()\n",
    "        mean_row.index = ['TS145']\n",
    "        mean_df = pd.concat([mean_df, mean_row], axis=1)\n",
    "\n",
    "        # 计算当前文件的最终最大 dockq 值，并将其存储到 final_max_dockq_df 中\n",
    "        final_max_row = pd.DataFrame({\n",
    "            'min_max': min_row.max(axis=1),\n",
    "            'max_max': max_row.max(axis=1),\n",
    "            'mean_max': mean_row.max(axis=1)\n",
    "        })\n",
    "        final_max_row.index = [target]\n",
    "        final_max_dockq_df = pd.concat([final_max_dockq_df, final_max_row])\n",
    "\n",
    "# 打印每个统计结果的 DataFrame\n",
    "print(\"Minimum values for each interface:\")\n",
    "print(min_df)\n",
    "print(\"\\nMaximum values for each interface:\")\n",
    "print(max_df)\n",
    "print(\"\\nMean values for each interface:\")\n",
    "print(mean_df)\n",
    "print(\"\\nFinal max dockq values for each target:\")\n",
    "print(final_max_dockq_df)\n",
    "# save final_max_dockq_df to \n",
    "final_max_dockq_df.to_csv(\"./for_Jing/TS145_dockq.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
